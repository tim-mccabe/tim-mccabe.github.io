<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Predicting Prices of Houses</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
  <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

  <!-- Custom styles for this template -->
  <link href="css/home_page.css" rel="stylesheet">

  <!-- Leaflet CSS -->
  <link rel="stylesheet" href="https://unpkg.com/leaflet@1.0.0-rc.3/dist/leaflet.css" />
  <script src="http://cdn.leafletjs.com/leaflet/v0.7.7/leaflet.js"></script>
  <script src='https://api.tiles.mapbox.com/mapbox.js/plugins/leaflet-omnivore/v0.3.1/leaflet-omnivore.min.js'></script>
  <link rel="stylesheet" href="https://unpkg.com/leaflet@1.0.3/dist/leaflet.css"/>
  <script src="https://unpkg.com/leaflet@1.0.3/dist/leaflet.js"></script>

</head>

<body>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand" href="index.html">Blog</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars" aria-hidden="true"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="about.html">Resume</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/tim-mccabe">GitHub</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="https://www.linkedin.com/in/tim-mccabe-88a0a091/">LinkedIn</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Header -->
  <header class="masthead" style="background-image: url('Images/housing.jpg')">
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="post-heading">
            <h1>Predicting Prices of Houses</h1>
            <h2 class="subheading">Kaggle House Prices Competition</h2>
            <span class="meta">Posted by
              <a href="#">Tim McCabe</a>
              on June 10, 2020</span>
          </div>
        </div>
      </div>
    </div>
  </header>
  
  <!-- Post Content -->
  <article>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <p>
            Similar to other machine learning blogs that I have posted, the same thought process will be applied to this new competition. The goal of this competition is to predict 
            the sales price for each house in the data set. The data set includes 79 explanatory variables describing almost every aspect of residential homes in Ames, Iowa.
          </p>

          <img class="img-fluid" src="Images/house_columns.jpg" alt="">

          <p>
              As you can see from the image from above, the data set is much more robust than the <a href="titanic.html">Titanic Competition</a>. However, from the description of the competition, 
              we know we will be focusing on different types of regression. In order to figure out what types of regressions to run, we must understand the data and providing 
              relavent visualizations of the data is very helpful. Below are just a few of the visualzations I created to help with my understanding of the data. To see all of more, 
              follow this link to <a href="https://www.kaggle.com/timmccabe/homepredictgn">my kaggle notebook</a>.
          </p>

          <img class="img-fluid" src="Images/sales_plot.jpg" alt="">

          <img class="img-fluid" src="Images/correlation_matrix.jpg" alt="">

          <img class="img-fluid" src="Images/correlation_matrix_small.jpg" alt="">

          <p>
              Correlation matrices are a great way to find patterns with any kind of numerical or quantitative data. With this kind of visualization it is pretty easy to see which 
              features to choose to run your different regressions on. There is some categorical data in this data set that could be useful for a more robust and in depth model. 
              This competition is also focused on advanced regression techniques like random forest and gradient boosting, so most of my model will be built around that for this 
              particular project. 
          </p>

          <p>
              In this competition, I had a chance to really dig deep into the different kinds of regressions and when each one is most effective for training models. Linear Regression 
              is probably the simplest model in Scikit-Learn's library. The LinearRegressor fits a linear model with coefficients w = (w1, â€¦, wp) to minimize the residual sum of squares 
              between the observed targets in the dataset, and the targets predicted by the linear approximation. 
          </p>

          <img class="img-fluid" src="Images/linear.png" alt="">

          <div class="img-label">
            <h5>
                Linear Regression Example
            </h5>
          </div>

          <p>
            Another common kind of regression that is very useful with this type of data is the Lasso regression.   
            The Lasso is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer non-zero coefficients, 
            effectively reducing the number of features upon which the given solution is dependent. For this reason Lasso and its variants are fundamental to the field of compressed 
            sensing. Under certain conditions, it can recover the exact set of non-zero coefficients. The implementation in the class Lasso uses coordinate descent as the algorithm 
            to fit the coefficients.
          </p>

          <img class="img-fluid" src="Images/lasso.png" alt="">

          <div class="img-label">
            <h5>
                Lasso Regression Example
            </h5>
          </div>

          <p>
            The Random Forest Regressor is essentially a large decision tree that uses data to make predictions, however it is a bit more sophisticated than a normal decision tree.
            A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy 
            and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.
          </p>

          <img class="img-fluid" src="Images/random_forest.jpg" alt="">

          <div class="img-label">
            <h5>
                Random Forest Regression Example
            </h5>
          </div>

          <p>
              The final regression I used in this competition was the Gradient Boosting Regressor. This is another form of decision tree similar to Random Forest but this involves loss functions. 
              Gradient Tree Boosting or Gradient Boosted Decision Trees (GBDT) is a generalization of boosting to arbitrary differentiable loss functions. GBDT is an accurate and effective off-the-shelf 
              procedure that can be used for both regression and classification problems in a variety of areas including Web search ranking and ecology.
          </p>

          <img class="img-fluid" src="Images/tree-infographic.jpg" alt="">

          <div class="img-label">
            <h5>
                Gradient Boosting Regression Example
            </h5>
          </div>

          <p>
              Once all of these models have been made, the next step is to combine or ensamble them to make the predictions as accurate as possible. The goal of ensemble methods is to combine the 
              predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator. There are two major 
              types of ensambling that are most used, averaging and boosting.  In averaging methods, the driving principle is to build several estimators independently and then to average their 
              predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced. By contrast, in boosting methods, base estimators 
              are built sequentially and one tries to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble. 
              Once this is done we can make our final predictions and submit them to the competition. 
          </p>

          <p>House Price Data Source by 
            <a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques">Kaggle via House Prices: Advanced Regression Techniques</a>.</p>
          <p>Information and definitions of algorithms sourced by  
            <a href="https://scikit-learn.org/stable/modules/linear_model.html">Scikit-Learn website</a>.</p>
        </div>
      </div>
    </div>
  </article>

  <hr>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <ul class="list-inline text-center">
            <li class="list-inline-item">
              <a href="https://www.kaggle.com/timmccabe">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-kaggle fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://www.linkedin.com/in/tim-mccabe-88a0a091/">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://github.com/tim-mccabe">
                <span class="fa-stack fa-lg">
                  <i class="fas fa-circle fa-stack-2x"></i>
                  <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                </span>
              </a>
            </li>
          </ul>
          <p class="copyright text-muted">Copyright Â© Tim McCabe</p>
        </div>
      </div>
    </div>
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/home_page.js"></script>

  <!-- Our JS -->


</body>

</html>